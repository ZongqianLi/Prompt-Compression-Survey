# Prompt Compression for Large Language Models: A Survey

## Examples

## Paper Overview

## Paper List

### Hard Prompt Methods:

- **Filtering:**

  - General: 

    - [SelectiveContext]
    - [LLMLingua]
    - [LongLLMLingua]
    - [AdaComp]

  - Distillation Enhanced:

    - [LLMLingua-2]

  - RL Enhanced: 

    - [TACO-RL]
    - [PCRL]

  - Embedding Enhanced:

    - [CPC]
    - [TCRA-LLM]

- **Paraphrasing:**
  - 123
    - [Nano-Capsulator]
    - [CompAct]
    - [FAVICOMP]

### Soft Prompt Methods:

- **Decoder Only:**

  - Not Finetuned:

    - [CC]

  - Finetuned:

    - [GIST]
    - [AutoCompressor]

- **Encoder-decoder:**

  - Both Finetuned:

    - [COCOM]
    - [LLoCO]

  - Finetuned Encoder:

    - [ICAE]
    - [500xCompressor]
    - [QGC]

  - Embedding Encoder:

    - [xRAG]

  - Projector:

    - [UniICL]

### Applications:

- **RAG:**

  - 123

    - [xRAG]
    - [RECOMP]
    - [COCOM]
    - [CompAct]
    - [FAVICOMP]
    - [AdaComp]
    - [LLoCO]
    - [TCRA-LLM]

- **Agents:**

  - 123

    - [HD-Gist]
    - []

- **Domain-specific tasks:**

  - 123

    - [Tag-llm]
    - [CoLLEGe]

- **Others:**

  - 123

    - [ICL] 
    - [Role Playing] 
    - [Functions] 













